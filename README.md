# üìä Telecom-X-parte2

Desafio do curso de **Data Science com Python** da Alura ‚Äî Parte 2: Machine Learning.

Este projeto analisa os dados da empresa de telecomunica√ß√µes **TelecomX**, que est√° enfrentando uma alta taxa de cancelamento de clientes. O objetivo √© identificar os fatores que influenciam a evas√£o e propor solu√ß√µes com base em modelos de aprendizado de m√°quina.

---

## üìÅ Estrutura do Projeto

- üîç An√°lise explorat√≥ria dos dados
- üßπ Limpeza e tratamento de dados
- üìä Visualiza√ß√µes
- ü§ñ Modelagem com Machine Learning
- ‚öñÔ∏è T√©cnicas de balanceamento de dados
- üìà Avalia√ß√£o de desempenho dos modelos

---

## üß™ Instru√ß√µes de Uso

1. Clone o reposit√≥rio:
   ```bash
   git clone [https://github.com/seu-usuario/TelecomX_Lparte2.git](https://github.com/bravo-ti/Telecom-X-part2)
   ```

2. Instale as depend√™ncias:
   ```bash
   pip install -r requirements.txt
   ```

3. Execute o notebook no [Google Colab](https://colab.research.google.com/) e clique em **"Executar tudo"**.

4. Bibliotecas utilizadas:
   ```python
   import pandas as pd
   import matplotlib.pyplot as plt
   import seaborn as sns
   import numpy as np
   ```

---

## üßπ Limpeza e Tratamento de Dados

- Os dados foram importados de uma API em formato JSON.
- O DataFrame original possui 7267 linhas e 6 colunas.
- As colunas com dicion√°rios foram normalizadas e concatenadas, resultando em um DataFrame final com 21 colunas.
- A coluna `'Charges.Total'` foi convertida para o tipo `float64`.

---

## üîç An√°lise Explorat√≥ria

- Foram criados dois grupos: clientes que cancelaram e clientes que permaneceram.
- A maioria dos cancelamentos ocorre no primeiro m√™s de uso (`tenure`).
- Visualiza√ß√µes foram geradas para entender padr√µes de evas√£o.

---

## ü§ñ Modelos de Machine Learning

### üìö Bibliotecas utilizadas

```python
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer, make_column_transformer
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import NearMiss
from imblearn.pipeline import Pipeline as imbpipeline
import pickle
```

---

## üìà Resultados dos Modelos

| Modelo           | Acur√°cia | Precis√£o | Recall | F1-Score |
|------------------|----------|----------|--------|----------|
| √Årvore de Decis√£o| 0.8017   | 0.6749   | 0.4884 | 0.5667   |
| KNN              | 0.7345   | 0.0000   | 0.0000 | 0.0000   |
| Random Forest    | 0.7747   | 0.8058   | 0.1996 | 0.3200   |

> ‚ö†Ô∏è O modelo KNN n√£o conseguiu generalizar bem os dados de treinamento.

---

## ‚öñÔ∏è Balanceamento de Dados

Foi utilizado o m√©todo **NearMiss** para lidar com o desbalanceamento entre classes.

### üìä M√©tricas ap√≥s Undersampling

| Classe | Precis√£o | Recall | F1-Score | Suporte |
|--------|----------|--------|----------|---------|
| 0      | 0.90     | 0.78   | 0.84     | 1552    |
| 1      | 0.56     | 0.76   | 0.64     | 561     |

- **Acur√°cia geral**: 0.77  
- **Intervalo de confian√ßa**: [0.4861, 0.9298]  
- **F1-Score m√©dio ponderado**: 0.78

---

## ü§ù Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas!  
Sinta-se √† vontade para abrir uma issue ou enviar um pull request.

---

